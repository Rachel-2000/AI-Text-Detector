# example of NLP attack with:
# transform methods: Word swapping
# constrains: embedding distance
# search methods: Greedy word swapping
import torch
import textattack
from transformers import BertTokenizer, BertForSequenceClassification

# Load model, tokenizer, and model_wrapper
model_path = "/content/drive/MyDrive/Colab Notebooks/repos/Bert-based-Text-Detection/best_model_v2.pt"
model = BertForSequenceClassification.from_pretrained("bert-base-uncased")
model.load_state_dict(torch.load(model_path))
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(model, tokenizer)

# Construct our four components for `Attack`
# 1. goal function
from textattack.attack_recipes import TextFoolerJin2019
# 2. constraints
from textattack.constraints.pre_transformation import RepeatModification, StopwordModification
from textattack.constraints.semantics import WordEmbeddingDistance
# 3. search methods
from textattack.search_methods import GreedyWordSwapWIR
# 4. transformation methods
from textattack.transformations import WordSwapEmbedding
from textattack import Attack

goal_function = textattack.goal_functions.UntargetedClassification(model_wrapper)
constraints = [
    RepeatModification(),
    StopwordModification(),
    WordEmbeddingDistance(min_cos_sim=0.9),
    ]
transformation = WordSwapEmbedding(max_candidates=50)
search_method = GreedyWordSwapWIR(wir_method="delete")
# Construct the actual attack
attack = Attack(goal_function, constraints, transformation, search_method)
input_text = "salt is good for not dying in car crashes and car crashes are worse for cars then salt . \
              Some places use other things , but salt is really cheap compared to most alternatives ,  \
              although sand is pretty good ."
label = 0 # negative (not generated by ChatGPT)
attack_result = attack.attack(input_text, label)
print(attack_result)